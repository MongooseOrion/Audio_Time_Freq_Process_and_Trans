# 基于 FPGA 的声音处理系统

针对多通道输入音频，实现实时的回声消除、噪声抑制、分离人声与背景音、声纹识别等功能，支持通过 UART 动态配置参数，并将数据以 UDP 发送至上位机。

  * 开发平台：紫光同创 PGL50H

## 仓库结构

```
|-- dataset                 // 深度学习数据集
|-- Document                // 相关技术文档和说明
|-- FPGA                    // 比特流文件、约束文件和 ROM 初始化文件
  |-- bitstream_backup      
|-- model                   // 深度学习模型文件
|-- Python                  // python 代码
  |-- gui_ctrl.py           // 上位机侧的控制程序
|-- RTL                     // RTL 代码
|-- Sample                  // 测试音频
|-- Software                // Matlab 仿真代码和相关系统控制程序
```

## 系统参数规格和功能指标

| 项目 | 参数 |
| :-- | :---: |
| 输入采样频率 | 48kHz |
| 输出采样频率 | 48kHz |
| 输入采样位深（量化位宽） | 16bit |
| 输出采样位深（量化位宽） | 16bit |
| 输入通道数 | 2-left, right |
| 输出通道数 | 1-left |
| 以太网传输等效位深 | 16bit |

受支持的功能：

  * 人声音调实时调整；
  * 抑制音频回音效果；
  * 音频中背景声抑制；
  * 分离背景声和人声；
  * 人声声纹识别；
  * 音频的流式传输（UDP）；
  * 串口功能控制；
  * 人声分类；
  * 音频分类、人声情绪和性别识别（调用[深度学习模型](#深度学习模型)）

## FPGA 资源利用情况

| 逻辑资源类别 | 使用量 | 使用百分比 |
| :--- | :---: | :---: |
| FF（Flip-Flops） | 11520 | 18 |
| LUT | 18111 | 42 | 
| LUT-FF pairs | 5285 | 12 |
| BRAM | 102 | 77 |
| 分布式 RAM | 239 | 2 |
| DLL（Delay Locked Loop）| 0 | 0 |
| PLL（Phase Locked Loop）| 4 | 80 |
| 算术运算单元（APM）| 36 | 43 |
| 时钟缓冲器（RCKB） | 0 | 0 |
| I/O Blocks Data | 18 | 29 |
| I/O Blocks Register | 4 | 27 |
| I/O Blocks Special | 115 | 53 |
| I/O Logic | 137 | 35 |
| 低压差稳压器（LDO） | 0 | 0 |

## 系统架构

系统通过 ES7243E ADC 模块将音频信号通过 3.5mm 耳机接口采样到开发板，在默认情况下，FPGA 本地处理音频的功能均被禁用，此时从 ADC 模块采样的数字信号的音频流直接通过 ES8156 DAC 模块输出模拟音频信号。

系统通过 UART 串口发送的命令来实现相关功能的启用和禁用，而通过以太网发送数据的功能始终启用，其数据源来自从 ADC 模块采样的原始数字信号，除非启用人声变声功能，此时以太网模块的输入数据来自人声变声模块输出的数据。

此外，经过处理的数据按照帧编组，与 FFT 处理信息一并输入 HDMI 显示模块以显示该帧的处理前后频谱幅值，同时接收声纹分类信息。系统拓扑图如下图所示。

<div align='center'><img src='./Document\pic\绘图3.png' width='600px' title='系统拓扑图'></div>

## 模块描述

你可以[点此](./Document/algorithm_specific.md)了解每个模块处理的实现原理。

### 回声消除模块

该模块用于抑制音频种的声学回声，可通过串口控制相关处理参数，实现对任意音频的回声抑制。

<div align='center'><img src='./Document\pic\绘图4.png' width='450px' title='回声消除模块结构图'></div>

### 人声变声模块

该模块用于调整人声声调，共有 2 种配置，可调得更高或者更低。

<div align='center'><img src='./Document\pic\绘图5.png' width='430px' title='人声变声模块结构图'></div>

### 背景噪声消除和多重声音分离模块

系统将**给定音频**在时域上分成多个处理段，在给定音频数据输入模块时，在每段音频处理段分别应用对应的频率抑制和提取配置，从而在整个音频上都有较为精确的去噪和声音提取效果。

<div align='center'><img src='./Document\pic\绘图8.png' width='550px' title='人声变声模块结构图'></div>

系统还加入了一个**自适应去除稳态噪声**的功能，当输入的音频的频率范围恒定时，可以抑制。

### 声纹识别模块

该模块用于识别给定音频的人声属于哪一个训练音频。系统采用梅尔倒谱系数（Mel-scale Frequency Cepstral Coefficients，MFCC）作为用于 VQ 计算的特征参数；采用 VQ-LBG 算法作为训练和识别的算法。**可实现即时训练和即时识别**。

<div align='center'><img src='./Document\pic\绘图12.png' width='600px' title='声纹识别模块结构图'></div>

### 录音模块

使用 DDR 缓存任意时长和任意分段音频数据（如果内存足够），可以通过 UART 指定要回放的音频索引。

### UART 模块

UART 模块用于接收由计算机发送的控制命令，以指示当前启用的功能，同时用于将声纹识别结果发送到计算机。你可以[点此](./Document\control_command.md)查看 UART 控制命令。

### 以太网数据发送模块

以太网数据发送模块用于将音频数据发送到计算机，以便执行深度学习推理任务。为避免传输出错和计算机 python 程序错误编码，系统使用段同步信号 `voice_vsync` 和帧有效信号 `voice_href` 来指示以太网模块发送数据，每段数据有 128 帧，每帧的宽度为 512 个时钟周期（即 512 个音频数据）；在每段数据的开头和结尾，系统加入了起始标识符：`FF B3`，终止标识符：`FF B4`。

### 人声分类模块

人声分类与声纹识别的不同点在于：声纹识别需要先验的特征向量（通过训练得到），然后将输入的特征向量与其相比较欧几里得几何距离，从而确认该声音是否属于先验特征向量所对应的人声；而人声分类则不会进行训练，直接对输入的音频进行分类。

该功能也采用 VQ-LBG 算法实现，算法原理[声纹识别](#声纹识别模块)的原理相同。然而，在 FPGA 实现时舍去了一些精度，从而无法满足无先验声纹类别的前提下将不同人声自动化分类的需要，因此该任务更适用于计算机处理。由于计算机可处理的数据精度更高，例如 `numpy.float64`，因此可用于实现人声分类。

### 深度学习模型

系统通过作者存储库中的[音频分类](https://github.com/MongooseOrion/Audio-Classification)项目实现了音频分类、变声检测、人声情绪和性别识别功能。为本项目预构建的模型文件位于 `./model` 文件夹内。你可以访问该仓库自行训练模型。

## 系统性能

### 延迟

| 键 | 模块主时钟 | 值 |
| :--- | :---: | :--- |
| 回声消除模块处理延迟 | 48kHz | 约 8000 个时钟周期 |
| 人声调整模块处理延迟 | 48kHz | 1024 个时钟周期 |
| 背景噪声消除模块处理延迟 | 48kHz | 512 个时钟周期 | 
| 多重声音分离模块处理延迟 | 48kHz | 512 个时钟周期 | 
| 声纹识别模块处理延迟 | 100MHz | 特征提取：约 30ms <br>训练：约 10ms <br>识别：约 2ms |
| 以太网数据发送模块处理延迟 | 1.536MHz | 约 1537 个时钟周期 |

### 准确度

| 键 | 值 |
| :--- | :--- |
| 声纹识别 | 98% |
| 人声分类 | 92% |

测试方法：在数据集中随机抽取 20 段 4 个人的声音，识别正确的数量与 20 的比值；进行 5 次测量取均值。